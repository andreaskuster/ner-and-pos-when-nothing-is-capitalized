{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "from nltk.corpus.reader import ConllCorpusReader\n",
    "from nltk.util import LazyMap, LazyConcatenation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class newConllReader(ConllCorpusReader):\n",
    "\n",
    "    def iob_words(self, fileids=None, tagset=None, column=\"chunk\"):\n",
    "        \"\"\"\n",
    "        :return: a list of word/tag/IOB tuples\n",
    "        :rtype: list(tuple)\n",
    "        :param fileids: the list of fileids that make up this corpus\n",
    "        :type fileids: None or str or list\n",
    "        \"\"\"\n",
    "        self._require(self.WORDS, self.POS, self.CHUNK)\n",
    "        def get_iob_words(grid):\n",
    "            return self._get_iob_words(grid, tagset, column)\n",
    "        return LazyConcatenation(LazyMap(get_iob_words, self._grids(fileids)))\n",
    "\n",
    "    def _get_iob_words(self, grid, tagset=None, column=\"chunk\"):\n",
    "        pos_tags = self._get_column(grid, self._colmap['pos'])\n",
    "        if tagset and tagset != self._tagset:\n",
    "            pos_tags = [map_tag(self._tagset, tagset, t) for t in pos_tags]\n",
    "        return list(zip(self._get_column(grid, self._colmap['words']),\n",
    "                   self._get_column(grid, self._colmap[column])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = newConllReader('../../ner_conll2003', 'eng.train', ['words', 'pos','chunk','ne']).iob_words(column='ne')\n",
    "test = newConllReader('../../ner_conll2003', 'eng.testa', ['words', 'pos','chunk','ne']).iob_words(column='ne')\n",
    "X_train, Y_train = [x[0] for x in train], [x[1] for x in train]\n",
    "X_test, Y_test = [x[0] for x in train], [x[1] for x in train]\n",
    "TAGS = list(set(Y_train)) \n",
    "TAGS2i = {TAGS[i]:i for i in range(len(TAGS))}\n",
    "words = list(set(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
